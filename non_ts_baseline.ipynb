{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-time series baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import holidays\n",
    "import lightgbm as lgb\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import gc\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df = pd.read_csv('data/load.csv')\n",
    "hierarchy_df = pd.read_csv(\"data/hierarchy.csv\")\n",
    "humidity_df = pd.read_csv(\"data/relative humidity.csv\")\n",
    "temperature_df = pd.read_csv(\"data/temperature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_formatting(load_df, hierarchy_df, humidity_df, temperature_df):\n",
    "    load_df = pd.melt(load_df, id_vars=[\"meter_id\", \"date\"], value_vars=load_df.columns.difference([\"meter_id\", \"date\"]), \n",
    "                                var_name=\"hour\", value_name=\"load\")\n",
    "    load_df[\"hour\"] = load_df[\"hour\"].str.strip(\"h\").astype(int) - 1\n",
    "    load_df[\"timestamp\"] = pd.to_datetime(load_df[\"date\"] + \" \" + load_df[\"hour\"].astype(str) + \":00:00\", format=\"%m/%d/%Y %H:%M:%S\")\n",
    "    load_df[\"meter_id\"] = load_df[\"meter_id\"].astype(int)\n",
    "    load_df = load_df.drop(columns=[\"date\", \"hour\"])\n",
    "    data_df = load_df.merge(hierarchy_df, on=\"meter_id\", how=\"left\")\n",
    "    data_df[hierarchy_df.columns.difference([\"meter_id\"])] = data_df[hierarchy_df.columns.difference([\"meter_id\"])].astype(str)\n",
    "    \n",
    "    humidity_df[\"timestamp\"] = pd.to_datetime(humidity_df[\"date\"] + \" \" + (humidity_df[\"hr\"] - 1).astype(str) + \":00:00\", format=\"%d%b%Y %H:%M:%S\")\n",
    "    temperature_df[\"timestamp\"] = pd.to_datetime(temperature_df[\"date\"] + \" \" + (temperature_df[\"hr\"] - 1).astype(str) + \":00:00\", format=\"%d%b%Y %H:%M:%S\")\n",
    "    humidity_df = humidity_df.drop(columns=[\"date\", \"hr\"])\n",
    "    temperature_df = temperature_df.drop(columns=[\"date\", \"hr\"])\n",
    "    data_df = data_df.merge(humidity_df, on=\"timestamp\", how=\"left\")\n",
    "    data_df = data_df.merge(temperature_df, on=\"timestamp\", how=\"left\")\n",
    "    return data_df\n",
    "\n",
    "joined_data_df = df_formatting(load_df, hierarchy_df, humidity_df, temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del load_df\n",
    "del hierarchy_df\n",
    "del humidity_df\n",
    "del temperature_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meter_id              int32\n",
       "load                float64\n",
       "timestamp    datetime64[ns]\n",
       "mid_level            object\n",
       "aggregate            object\n",
       "rh_ws1              float64\n",
       "rh_ws2              float64\n",
       "rh_ws3              float64\n",
       "rh_ws4              float64\n",
       "rh_ws5              float64\n",
       "rh_ws6              float64\n",
       "rh_ws7              float64\n",
       "rh_ws8              float64\n",
       "rh_ws9              float64\n",
       "rh_ws10             float64\n",
       "rh_ws11             float64\n",
       "rh_ws12             float64\n",
       "rh_ws13             float64\n",
       "rh_ws14             float64\n",
       "rh_ws15             float64\n",
       "rh_ws16             float64\n",
       "rh_ws17             float64\n",
       "rh_ws18             float64\n",
       "rh_ws19             float64\n",
       "rh_ws20             float64\n",
       "rh_ws21             float64\n",
       "rh_ws22             float64\n",
       "rh_ws23             float64\n",
       "rh_ws24             float64\n",
       "rh_ws25             float64\n",
       "rh_ws26             float64\n",
       "rh_ws27             float64\n",
       "rh_ws28             float64\n",
       "t_ws1               float64\n",
       "t_ws2               float64\n",
       "t_ws3               float64\n",
       "t_ws4               float64\n",
       "t_ws5               float64\n",
       "t_ws6               float64\n",
       "t_ws7               float64\n",
       "t_ws8               float64\n",
       "t_ws9               float64\n",
       "t_ws10              float64\n",
       "t_ws11              float64\n",
       "t_ws12              float64\n",
       "t_ws13              float64\n",
       "t_ws14              float64\n",
       "t_ws15              float64\n",
       "t_ws16              float64\n",
       "t_ws17              float64\n",
       "t_ws18              float64\n",
       "t_ws19              float64\n",
       "t_ws20              float64\n",
       "t_ws21              float64\n",
       "t_ws22              float64\n",
       "t_ws23              float64\n",
       "t_ws24              float64\n",
       "t_ws25              float64\n",
       "t_ws26              float64\n",
       "t_ws27              float64\n",
       "t_ws28              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "joined_data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # Basic feature engineering: indicator of day of the week, month, is_holiday (in MA), one-hot encoding of hierarchies and of the meter id\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    holidays_MA = holidays.US(years=range(2005, 2012), state=\"MA\")\n",
    "    df['is_holiday'] = df['timestamp'].dt.date.isin(holidays_MA.keys())\n",
    "    #df['holiday_name'] = df.apply(lambda row: \"None\" if not df['is_holiday'] else holidays_MA[row[\"timestamp\"].date()], axis=1): too slow, to be optimized\n",
    "    df = df.drop(columns=[\"timestamp\"])\n",
    "\n",
    "    #meter_onehot = pd.get_dummies(df['meter_id'], drop_first=True, prefix=\"meter\")\n",
    "    #mid_level_onehot = pd.get_dummies(df['mid_level'], drop_first=True, prefix=\"mid_level\")\n",
    "    #aggregate_onehot = pd.get_dummies(df['aggregate'], drop_first=True, prefix=\"aggregate\")\n",
    "    #month_onehot = pd.get_dummies(df['month'], drop_first=True, prefix=\"month\")\n",
    "    #dow_onehot = pd.get_dummies(df['day_of_week'], drop_first=True, prefix=\"dow\")\n",
    "    #df = df.drop(columns=[\"meter_id\", \"mid_level\", \"aggregate\", \"month\", \"day_of_week\"])\n",
    "    #features_df = pd.concat([df, meter_onehot, mid_level_onehot, aggregate_onehot, month_onehot, dow_onehot], axis=1)\n",
    "    #return features_df\n",
    "    return df\n",
    "\n",
    "transformed_data_df = feature_engineering(joined_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meter_id', 'load', 'mid_level', 'aggregate', 'rh_ws1', 'rh_ws2',\n",
       "       'rh_ws3', 'rh_ws4', 'rh_ws5', 'rh_ws6', 'rh_ws7', 'rh_ws8', 'rh_ws9',\n",
       "       'rh_ws10', 'rh_ws11', 'rh_ws12', 'rh_ws13', 'rh_ws14', 'rh_ws15',\n",
       "       'rh_ws16', 'rh_ws17', 'rh_ws18', 'rh_ws19', 'rh_ws20', 'rh_ws21',\n",
       "       'rh_ws22', 'rh_ws23', 'rh_ws24', 'rh_ws25', 'rh_ws26', 'rh_ws27',\n",
       "       'rh_ws28', 't_ws1', 't_ws2', 't_ws3', 't_ws4', 't_ws5', 't_ws6',\n",
       "       't_ws7', 't_ws8', 't_ws9', 't_ws10', 't_ws11', 't_ws12', 't_ws13',\n",
       "       't_ws14', 't_ws15', 't_ws16', 't_ws17', 't_ws18', 't_ws19', 't_ws20',\n",
       "       't_ws21', 't_ws22', 't_ws23', 't_ws24', 't_ws25', 't_ws26', 't_ws27',\n",
       "       't_ws28', 'year', 'month', 'day_of_week', 'is_holiday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(transformed_data):\n",
    "    train_df = transformed_data[transformed_data[\"year\"] < 2011]\n",
    "    test_df = transformed_data[transformed_data[\"year\"] == 2012]\n",
    "    return train_df, test_df\n",
    "train_df, test_df = train_test_split(transformed_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a LightGBM model with default hyperparameters\n",
    "def print_progress(iteration):\n",
    "    print(iteration)\n",
    "    \n",
    "X_train = train_df[train_df.columns.difference([\"load\"])]\n",
    "feature_names = list(X_train.columns)\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = train_df[\"load\"]\n",
    "del train_df\n",
    "gc.collect()\n",
    "X_test = test_df[test_df.columns.difference([\"load\"])]\n",
    "y_test = test_df[\"load\"]\n",
    "\n",
    "params = {\"objective\": \"regression\", \"metric\": \"mse\"}\n",
    "train_data = lgb.Dataset(X_train, label=y_train, feature_name = feature_names, categorical_feature = [\"meter_id\", \"mid_level\", \"aggregate\", \"month\", \"day_of_week\"], callbacks=[(print_progress)])\n",
    "num_round = 100\n",
    "bst_model = lgb.train(params, train_data, num_round)\n",
    "y_pred = bst_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error on the test set: \"+\"{:.3f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal hyperparameter tuning with FLAML\n",
    "config = {\n",
    "    \"time_budget\": 3600,  # one hour time budget\n",
    "    \"metric\": 'mse',\n",
    "    \"task\": 'regression',\n",
    "    \"estimator_list\": ['lgbm'],\n",
    "}\n",
    "\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, **config)\n",
    "best_model = automl.best_model\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error on the test set: \"+\"{:.3f}\".format(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
